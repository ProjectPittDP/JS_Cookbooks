{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://python.langchain.com/v0.1/docs/use_cases/graph/constructing/\n",
    "\n",
    "! pip install --upgrade --quiet  langchain langchain-community langchain-openai langchain-experimental neo4j json-repair langsmith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langsmith import traceable\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "#langchain key is already set in .bashrc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "\n",
    "os.environ[\"NEO4J_URI\"] = \"bolt://localhost:7687\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"neo4j\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"password\"\n",
    "\n",
    "#see additional env variables in the docker setup below from LC\n",
    "#https://python.langchain.com/v0.1/docs/integrations/graphs/neo4j_cypher/\n",
    "\n",
    "graph = Neo4jGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain.chat_models.ollama import ChatOllama\n",
    "\n",
    "\n",
    "#llm = ChatOllama(model=\"smangrul/llama-3-8b-instruct-function-calling\")\n",
    "llm = ChatOllama(model=\"phi3\")\n",
    "\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "text = \"\"\"\n",
    "Marie Curie, born in 1867, was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity.\n",
    "She was the first woman to win a Nobel Prize, the first person to win a Nobel Prize twice, and the only person to win a Nobel Prize in two scientific fields.\n",
    "Her husband, Pierre Curie, was a co-winner of her first Nobel Prize, making them the first-ever married couple to win the Nobel Prize and launching the Curie family legacy of five Nobel Prizes.\n",
    "She was, in 1906, the first woman to become a professor at the University of Paris.  Joan Bonet is the first woman to win a gold medal in shotput.  She is best friends with Pierre Curie.\n",
    "\"\"\"\n",
    "#Joan Bonet is the first woman to win a gold medal in shotput.  She is best friends with Pierre Curie.\n",
    "print(\"Loading document...\")\n",
    "documents = [Document(page_content=text)]\n",
    "print(\"Document sucessfully loaded\")\n",
    "\n",
    "print(\"Converting document to neo4j graph...\")\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "print(\"Neo4j schema successfully created \")\n",
    "\n",
    "print(\"Loading graph into neo4j\")\n",
    "graph.add_graph_documents(graph_documents)\n",
    "print(\"Graph successfully loaded\")\n",
    "#print(f\"Nodes:{graph_documents[0].nodes}\")\n",
    "#print(f\"Relationships:{graph_documents[0].relationships}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents[0].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"/home/jonot480/Documents/jon craig.txt\")\n",
    "doc_text = loader.load()\n",
    "text=doc_text[0].page_content\n",
    "documents = [Document(page_content=text)]#there may be an easier way to feed this, but i'm just using the langchain docs \n",
    "print(documents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_graph_documents(graph_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_transformer_filtered = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    allowed_nodes=[\"Person\", \"Country\", \"Organization\"],\n",
    "    allowed_relationships=[\"NATIONALITY\", \"LOCATED_IN\", \"WORKED_AT\", \"SPOUSE\"],\n",
    ")\n",
    "graph_documents_filtered = llm_transformer_filtered.convert_to_graph_documents(\n",
    "    documents\n",
    ")\n",
    "print(f\"Nodes:{graph_documents_filtered[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents_filtered[0].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you need an LLM that can run function calling/tools\n",
    "#open ai supports this, but you need something like nous hermes or llama3 \n",
    "#phi3 doesn't seem to work \n",
    "#https://www.reddit.com/r/LocalLLaMA/comments/1cl6ocx/llm_with_function_calling_only_openai_models_have/\n",
    "\n",
    "llm_transformer_props = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    allowed_nodes=[\"Person\", \"Country\", \"Organization\"],\n",
    "    allowed_relationships=[\"NATIONALITY\", \"LOCATED_IN\", \"WORKED_AT\", \"SPOUSE\"],\n",
    "    node_properties=[\"born_year\"],\n",
    ")\n",
    "\n",
    "graph_documents_props = llm_transformer_props.convert_to_graph_documents(documents)\n",
    "print(f\"Nodes:{graph_documents_props[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents_props[0].relationships}\")\n",
    "\n",
    "graph.add_graph_documents(graph_documents_props)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
